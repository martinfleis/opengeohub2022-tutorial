{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenGeoHub Summer School 2022 - Introduction to GeoPandas and its Python ecosystem\n",
    "\n",
    "**Martin Fleischmann**\n",
    "\n",
    "<sup>1</sup>Geographic Data Science Lab, University of Liverpool, UK<br>\n",
    "<sup>2</sup>Urban and Regional Laboratory, Charles University, CZ<br>\n",
    "<sup>3</sup>UrbanDataLab AG, Zürich, CH\n",
    "\n",
    "31/08/2022, Siegburg\n",
    "\n",
    "## Setup\n",
    "\n",
    "Follow the Readme to set-up the environment correctly. You should have these packages installed:\n",
    "\n",
    "```\n",
    "- geopandas\n",
    "- dask-geopandas\n",
    "- pyogrio\n",
    "- pyarrow\n",
    "- python-graphviz\n",
    "- esda\n",
    "- momepy\n",
    "- libpysal\n",
    "- dask-labextension # optionally, if using JupyterLab\n",
    "```\n",
    "\n",
    "## What is GeoPandas\n",
    "\n",
    "GeoPandas, as the name suggests, extends the popular data science library [pandas](https://pandas.pydata.org) by adding support for geospatial data.\n",
    "\n",
    "The core data structure in GeoPandas is the `geopandas.GeoDataFrame`, a subclass of `pandas.DataFrame`, that can store geometry columns and perform spatial operations. The `geopandas.GeoSeries`, a subclass of `pandas.Series`, handles the geometries. Therefore, your `GeoDataFrame` is a combination of `pandas.Series`, with traditional data (numerical, boolean, text etc.), and `geopandas.GeoSeries`, with geometries (points, polygons etc.). You can have as many columns with geometries as you wish; there's no limit typical for desktop GIS software.\n",
    "\n",
    "![geodataframe schema](fig/dataframe.svg)\n",
    "\n",
    "Each `GeoSeries` can contain any geometry type (you can even mix them within a single array) and has a `GeoSeries.crs` attribute, which stores information about the projection (CRS stands for Coordinate Reference System). Therefore, each `GeoSeries` in a `GeoDataFrame` can be in a different projection, allowing you to have, for example, multiple versions (different projections) of the same geometry.\n",
    "\n",
    "Only one `GeoSeries` in a `GeoDataFrame` is considered the _active_ geometry, which means that all geometric operations applied to a `GeoDataFrame` operate on this _active_ column.\n",
    "\n",
    "But when we talk about GeoPandas, we first have to talk about pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is pandas?\n",
    "\n",
    "Once again, the best place to ask this question is the documentation.\n",
    "\n",
    "> `pandas` is an open source library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "\n",
    "What that means in practice? Pandas provides two key data structures - a `Series` and a `DataFrame`. Since you will mostly work with DataFrames, composed of Series, we can start with that.\n",
    "\n",
    "![dataframe](fig/01_table_dataframe.svg)\n",
    "\n",
    "### Reading and writing\n",
    "\n",
    "We can start quickly illustrating pandas in practice by reading some files. While pandas can read many file formats, we can keep it simple and read a CSV.\n",
    "\n",
    "![io](fig/02_io_readwrite.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with some demographic characteristics in Liverpool, borrowed from a [Geographic Data Science](https://darribas.org/gds_course/content/bB/lab_B.html) course by [Dani Arribas-Bel](http://twitter.com/darribas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop = pandas.read_csv(\n",
    "    \"https://darribas.org/gds_course/content/data/liv_pop.csv\",  # path to the file\n",
    "    index_col=\"GeographyCode\",  # column to use as an index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how the data looks like by simply typing its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each column or row is a `Series` object, which we can access based on a name, a location or other means.\n",
    "\n",
    "![subset](fig/03_subset_columns_rows.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop[\"Middle East and Asia\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further use the columns to do algebra on them or turn them into boolean masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop[\"Middle East and Asia\"] > 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where boolen masks can be used to filter the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop[liv_pop[\"Middle East and Asia\"] > 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And combine masks along rows with explicit list of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop.loc[\n",
    "    liv_pop[\"Middle East and Asia\"] > 500, [\"Africa\", \"The Americas and the Caribbean\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can also combine columns to create a new one. What is the total population of each LSOA?\n",
    "\n",
    "![new column](fig/05_newcolumn_2.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = liv_pop.sum(axis=1)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop[\"Total\"] = total\n",
    "liv_pop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also quickly visualize the data. (But not on a map yet, that is where GeoPandas comes in.)\n",
    "\n",
    "![plot](fig/04_plot_overview.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop[\"Total\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop.plot.scatter(\"Africa\", \"Middle East and Asia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's go back to GeoPandas!**\n",
    "\n",
    "If you look again at the diagram shown above (and here once again), you now undestand that both `index` and `data` are a practically a `pandas.DataFrame`. But what else is happenning there?\n",
    "\n",
    "![geodataframe schema](fig/dataframe.svg)\n",
    "\n",
    "\n",
    "## The pieces we bring together\n",
    "\n",
    "Any software that has an ambition to properly deal with geospatial data needs to cover four aspects:\n",
    "\n",
    "- *data*\n",
    "    - We just learned that this part is covered by `pandas`.\n",
    "- *geometry*\n",
    "    - Handling of the actual geometries and operations on them. In FOSS, there is one leading engine, `GEOS`, but given it is written in C++, we need a Python wrapper. That is called `shapely`.\n",
    "- *projections*\n",
    "    - We need to know which place on the Earth (or other planet) each coordinates refer to. That is what projections, or Coordinate Reference Systems (CRS), take care of. The main FOSS engine here is `PROJ`, again written in C++ and in Python wrapped by `pyproj`.\n",
    "- *reading and writing files*\n",
    "    - Geospatial world knows a lot of file formats to store the data, from Shapefile and GeoJSON to GeoParquet. The best way to read and write into them is to use `GDAL/OGR`, another C++ library, which is avaliable either via `fiona` or recently via `pyogrio`.\n",
    "\n",
    "![ecosystem diagram](fig/ecosystem.png)\n",
    "\n",
    "Let's see all of them in action within GeoPandas.\n",
    "\n",
    "## GeoPandas in action\n",
    "\n",
    "First, we need to read some data.\n",
    "\n",
    "### Reading files\n",
    "\n",
    "Assuming you have a file containing both data and geometry (e.g. GeoPackage, GeoJSON, Shapefile), you can read it using `geopandas.read_file()`, which automatically detects the filetype and creates a `GeoDataFrame`. This can use either `fiona` or `pyogrio` as an engine (as of GeoPandas 0.11) interfacing GDAL/OGR to do the heavy lifting. We use `pyogrio` as a newer, faster option.\n",
    "\n",
    "We will again borrow data from the [GDS course](https://darribas.org/gds_course/content/bC/lab_C.html#cities) we used before. This time we load the boundaries of Spanish cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "\n",
    "cities = geopandas.read_file(\"https://ndownloader.figshare.com/files/20232174\")\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing files\n",
    "\n",
    "To write a `GeoDataFrame` back to file use `GeoDataFrame.to_file()`. The file is format automatically inferred from the suffix, but you can specify your own with the `driver` keyword. When no suffix is given, GeoPandas expects you want a folder with ESRI Shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.to_file(\"cities.gpkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometries\n",
    "\n",
    "Geometries within the *geometry* column are `shapely` objects. GeoPandas itself is not creating the object but leverages the existing ecosystem (note that there is a significant overlap of the team writing both to ensure synergy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cities.geometry.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.geometry.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.geometry.loc[0].wkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But without an assigned CRS, we don't know where on the Earth this shape lies. Therefore, each geometry column has (optionally) assigned one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cities.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see how the whole ecosystem comes together.\n",
    "\n",
    "### Simple accessors and methods\n",
    "\n",
    "Now we have our `GeoDataFrame` and can start working with its geometry. \n",
    "\n",
    "Since there was only one geometry column in the Spanish cities dataset, this column automatically becomes the _active_ geometry and spatial methods used on the `GeoDataFrame` will be applied to the `\"geometry\"` column.\n",
    "\n",
    "#### Measuring area\n",
    "\n",
    "To measure the area of each polygon, access the `GeoDataFrame.area` attribute, which returns a `pandas.Series`. Note that `GeoDataFrame.area` is just `GeoSeries.area` applied to the _active_ geometry column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"area\"] = cities.area\n",
    "cities[\"area\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting polygon boundary and centroid\n",
    "\n",
    "To get the boundary of each polygon (LineString), access the `GeoDataFrame.boundary`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"boundary\"] = cities.boundary\n",
    "cities[\"boundary\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have saved boundary as a new column, we now have two geometry columns in the same `GeoDataFrame`.\n",
    "\n",
    "We can also create new geometries, which could be, for example, a buffered version of the original one (i.e., `GeoDataFrame.buffer(10)`) or its centroid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"centroid\"] = cities.centroid\n",
    "cities[\"centroid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring distance\n",
    "\n",
    "We can also measure how far each centroid is from the first centroid location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_point = cities[\"centroid\"].iloc[0]\n",
    "cities[\"distance\"] = cities[\"centroid\"].distance(first_point)\n",
    "cities[\"distance\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `geopandas.GeoDataFrame` is a subclass of `pandas.DataFrame`, so we have all the pandas functionality available to use on the geospatial dataset — we can even perform data manipulations with the attributes and geometry information together.\n",
    "\n",
    "For example, to calculate the average of the distances measured above, access the `\"distance\"` column and call the `mean()` method on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities[\"distance\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making maps\n",
    "\n",
    "GeoPandas can also plot maps, so we can check how the geometries appear in space. To plot the active geometry, call `GeoDataFrame.plot()`. To color code by another column, pass in that column as the first argument. In the example below, we plot the active geometry column and color code by the `\"area\"` column. We also want to show a legend (`legend=True`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.plot(\"area\", legend=True, figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Other resources for plotting\n",
    "\n",
    "Want to know more on static plots? Check [this chapter](https://darribas.org/gds_course/content/bC/lab_C.html#styling-plots) of the GDS course or [the GeoPandas documentation](https://geopandas.org/en/stable/docs/user_guide/mapping.html).\n",
    "</div>\n",
    "\n",
    "You can also explore your data interactively using `GeoDataFrame.explore()`, which behaves in the same way `plot()` does but returns an interactive (leaflet.js) map instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.explore(\"area\", legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switching the active geometry (`GeoDataFrame.set_geometry`) to centroids, we can plot the same data using point geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities.set_geometry(\"centroid\")\n",
    "cities.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can also layer both `GeoSeries` on top of each other. We just need to use one plot as an axis for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = cities[\"geometry\"].explore()\n",
    "cities[\"centroid\"].explore(m=m, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the active geometry back to the original `GeoSeries`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = cities.set_geometry(\"geometry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial predicates\n",
    "\n",
    "Spatial predicates tell us what is the spatial relation between two geometries. Are they equal, do they intersects, overlap, is one wihtin another?\n",
    "\n",
    "For this part we use a toy datasets that come with GeoPandas, so we just need to retrive their location within the package installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_countries = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "world_cities = geopandas.read_file(geopandas.datasets.get_path('naturalearth_cities'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = world_countries.explore()\n",
    "world_cities.explore(m=m, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create some small toy spatial objects:\n",
    "\n",
    "A polygon <small>(note: we use `.item()` here to to extract the scalar geometry object from the GeoSeries of length 1)</small>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium = world_countries.loc[world_countries['name'] == 'Belgium', 'geometry'].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paris = world_cities.loc[world_cities['name'] == 'Paris', 'geometry'].item()\n",
    "brussels = world_cities.loc[world_cities['name'] == 'Brussels', 'geometry'].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a linestring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "\n",
    "line = LineString([paris, brussels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize those 4 geometry objects together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geopandas.GeoSeries([belgium, paris, brussels, line], crs=world_cities.crs).explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can recognize the abstract shape of Belgium.\n",
    "\n",
    "Brussels, the capital of Belgium, is thus located within Belgium. This is a spatial relationship, and we can test this using the individual shapely geometry objects as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brussels.within(belgium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And using the reverse, Belgium contains Brussels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium.contains(brussels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, Paris is not located in Belgium:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium.contains(paris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paris.within(belgium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The straight line we draw from Paris to Brussels is not fully located within Belgium, but it does intersect with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "belgium.contains(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.intersects(belgium)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial relationships with GeoDataFrames\n",
    "\n",
    "The same methods that are available on individual `shapely` geometries as we have seen above, are also available as methods on `GeoSeries` / `GeoDataFrame` objects.\n",
    "\n",
    "For example, if we call the `contains` method on the world dataset with the `paris` point, it will do this spatial check for each country in the `world` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_countries.contains(paris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the above gives us a boolean result, we can use that to filter the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_countries[world_countries.contains(paris)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also do the same based on a query over the spatial index. Custom queries on spatial index using `query` and esp. `query_bulk` are often much faster but are also considered an advanced usage. Since GeoPandas wraps them in spatial joins covering most of the cases, you may not even need to access `sindex` directly yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_countries.iloc[world_countries.sindex.query(paris, \"within\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial join\n",
    "\n",
    "One of he most typical geospatial tasks is a spatial join. Let's go back to our dataset with the Spanish city boundaries and try to figure out which of these cities fall into Catalonia region and which province they belong to.\n",
    "\n",
    "First, we need a data representing Catalonia. We get one directly from the Catalonian open data portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalonia = geopandas.read_file(\n",
    "    \"https://analisi.transparenciacatalunya.cat/api/geospatial/ghr8-wp3h?method=export&format=Shapefile\",\n",
    ")\n",
    "catalonia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the CRS, because for spatial join, we need to be sure that both GeoDataFrames are using the same (but don't worry, GeoPandas would warn you in case of a CRS mismatch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalonia.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this one is different, we can re-project the geometries to the CRS of `cities`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalonia = catalonia.to_crs(cities.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can do the spaital join using the `sjoin` method. That by default uses the `intersects` predicate but you can use any of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia = cities.sjoin(catalonia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cities_within_catalonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia.explore(\n",
    "    \"nom_prov\",\n",
    "    tiles=\"Stamen Toner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since GeoDataFrames are still based on pandas DataFrames, we can readily use pandas functionality, like `groupby` on the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_within_catalonia.groupby(\"nom_prov\").area.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay\n",
    "\n",
    "In some cases, we may want to create new geometries based on their spatial relationships between existing geometries. We call these _overlay_ operations.\n",
    "\n",
    "Let's assume that we are interested in areas that are 10km around a centroid of each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_centroids = cities['centroid'].buffer(10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffered_centroids.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can ask for an intersection between the buffer and city boundaries.\n",
    "\n",
    "![intersection](https://geopandas.org/en/stable/_images/binary_geo-intersection.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.overlay(buffered_centroids.to_frame(), how=\"intersection\").explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we may want to do the union of the two to get area covered either by distance or the boundary.\n",
    "\n",
    "![union](https://geopandas.org/en/stable/_images/binary_geo-union.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.overlay(buffered_centroids.to_frame(), how=\"union\").explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or do the difference. Find all parts of boundaries that are further away than 10km from each centroid.\n",
    "\n",
    "![difference](https://geopandas.org/en/stable/_images/binary_geo-difference.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.overlay(buffered_centroids.to_frame(), how=\"difference\").explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we may as which parts areas are either wihtin 10km or wihtin a boundary but not both.\n",
    "\n",
    "![difference](https://geopandas.org/en/stable/_images/binary_geo-symm_diff.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.overlay(buffered_centroids.to_frame(), how=\"symmetric_difference\").explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ecosystem\n",
    "\n",
    "We can now move beyond GeoPandas, because while being useful itself, its main benefit is that it enables others to build on top of a robust basis. We can take an example of PySAL, Python Spatial Analysis Library. PySAL is a federation of 21 individual packages covering everything from basic spatial weights matrices to spatial regression, optimisation, point pattern analysis or dasymetric mapping.\n",
    "\n",
    "Today, we will look at two of them to learn how to work with spatial weights and how to measure local index of spatial autocorrelatoin (LISA).\n",
    "\n",
    "Let's go back to our LSOA-based data from Liverpool. This time, we load the geometries using geopandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa = geopandas.read_file(\n",
    "    \"https://darribas.org/gds_course/content/data/liv_lsoas.gpkg\",\n",
    ")\n",
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial weights\n",
    "\n",
    "Spatial weights can be created in many ways based on many conditions. We are now intersted in the most common one - contiguity. We simply want to encode, which geometries are neighbours of which.\n",
    "\n",
    "To generate such a matrix, we can use the `weights` module of `libpysal` and its `Queen` contiguity implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal import weights\n",
    "\n",
    "w_queen = weights.Queen.from_dataframe(liv_lsoa, idVariable=\"LSOA11CD\")\n",
    "w_queen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we have used the LSOA code to encode the spatial weights. To make it a bit easier below, let's set the same variable as an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa = liv_lsoa.set_index(\"LSOA11CD\")\n",
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can explore what `w_queen` object actually contains. We can pick one LSOA, say `E01006690` and check its neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen[\"E01006690\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number `1.0` encodes the strength, because weights can be more complex than simple boolean \"is neighbor\" or \"is not\". It can potentially be weighted based on the lenght of the common boundary.\n",
    "\n",
    "We can also quickly check how many neighbours it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.cardinalities[\"E01006524\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if it is more or less than the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.mean_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check this on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa = \"E01006690\"\n",
    "\n",
    "m = liv_lsoa.loc[[lsoa]].explore(color=\"red\")\n",
    "liv_lsoa.loc[w_queen[lsoa].keys()].explore(m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use other ways of creating weights. For example K-nearest neighbors or a distance band.\n",
    "\n",
    "We can find 10 nearest neighbors (based on the centroid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_knn = weights.KNN.from_dataframe(liv_lsoa, k=10, ids=liv_lsoa.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa = \"E01006690\"\n",
    "\n",
    "m = liv_lsoa.loc[[lsoa]].explore(color=\"red\")\n",
    "liv_lsoa.loc[w_knn[lsoa].keys()].explore(m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or all neighbours within 2 kilometres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_2km = weights.DistanceBand.from_dataframe(liv_lsoa, threshold=2000, ids=liv_lsoa.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoa = \"E01006690\"\n",
    "\n",
    "m = liv_lsoa.loc[[lsoa]].explore(color=\"red\")\n",
    "liv_lsoa.loc[w_2km[lsoa].keys()].explore(m=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial lag\n",
    "\n",
    "Now, remember that we also had some data for these areas. Let's compare the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One has geometries but no data, the other has data but no geometries. But both share the LSOA code we can use to merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa = liv_lsoa.merge(liv_pop, left_on=\"LSOA11CD\", right_on=\"GeographyCode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the very useful things we can do with spatial weights is to calculate a spatial lag. That is, in principle, a mean of values from neighbouring geometries.\n",
    "\n",
    "We can measure it easily using `lag_spatial` function. But before that, we need to transform the weights so the all weights (the numbers) for each geometry sum up to one. Otherwise we would measure the sum of instead of mean.\n",
    "\n",
    "Weights before the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_queen.weights['E01006512']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row-wise transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.transform = \"R\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights after the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen.weights['E01006512']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can measure the lag. For example of the `\"Middle East and Asia\"` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen_score = weights.lag_spatial(w_queen, liv_lsoa[\"Middle East and Asia\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_queen_score[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assign it to the dataframe as a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa[\"Middle East and Asia lagged\"] = w_queen_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moran plot\n",
    "\n",
    "With the spatial lag, we can start asking some spatial questions. Like, is there a spatial autocorrelation? The simplest way of getting a sense on that is to plot the original variable against its spatial lag, so called Moran plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.plot.scatter(\n",
    "    \"Middle East and Asia\", \"Middle East and Asia lagged\", figsize=(8, 8)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there is a relationship between the two, we can assume spatial autocorrelation of the variable. And here it seems that there is a strong one.\n",
    "\n",
    "### LISA\n",
    "\n",
    "We can explore that further, using the Local Indicator of Spatial Autocorrelation (LISA), implemented in another of PySAL's packages called `esda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.moran import Moran_Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do the actual measuring, we should normalise the values as some of the LSOAs have larger total population than the others and it would skew the output. We can rather look at proportions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa[\"Middle East and Asia proportion\"] = (\n",
    "    liv_lsoa[\"Middle East and Asia\"] / liv_lsoa[\"Total\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our existing spatial weights, pass the variable and measure the LISA based on Moran's I using the `Moran_Local` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc = Moran_Local(liv_lsoa[\"Middle East and Asia proportion\"], w_queen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now explore the object. \n",
    "\n",
    "First, a LISA quadrant encoding if the geometry has high values and is surrounded by other of high values or any other combination of high and low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc.q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a simulated P value indicating significance of the result for each geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is enough for us to plot the result and see whether there are any hotspots where Asian and Middle East population tend to live or any cold spots they are not present in.\n",
    "\n",
    "For easier reading we can relabel the quadrants with self-explanatory labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_labels = {\n",
    "    1: \"High-high\",\n",
    "    2: \"Low-high\",\n",
    "    3: \"Low-low\",\n",
    "    4: \"High-low\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can just assign the quadrants and P-values as columns, filter based on significance and look at the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa[\"moran_q\"] = moran_loc.q\n",
    "liv_lsoa[\"moran_q\"] = liv_lsoa[\"moran_q\"].map(moran_labels)\n",
    "liv_lsoa[\"moran_p\"] = moran_loc.p_sim\n",
    "liv_lsoa.loc[liv_lsoa[\"moran_p\"] > 0.05, \"moran_q\"] = None  # filter by significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.explore(\"moran_q\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quilckly compare the quadrants to the actual distribution, to see if it \"makes sense\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.explore(\"Middle East and Asia proportion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to take these clusters and get only their boundaries. In practice, we want to _union_ all the geometries belonging to a single class. That is where GeoPandas is comes useful again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_lsoa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GeoPandas has a built in method for this spatial groupby, called `dissolve`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = liv_lsoa.dissolve(\"moran_q\")\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, we have mutli polygons, one geometry per class. Let's say we want each location on its own. We want to _explode_ the geometries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_individual = clusters.explode(index_parts=True)\n",
    "clusters_individual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A small exercise\n",
    "\n",
    "You can later check if we can see similar patterns for other demographic groups, how do they change based on different spatial weights types (Queen, KNN, DistanceBand...). You can also play with overlay on top of resuling dissolved polygons to find the most common areas that belong to different quadrants (or you can try to do that based on attributes and compare).\n",
    "\n",
    "## Going big\n",
    "\n",
    "We are entering the last part of the tutorial. This even may be a homework for you, depends on the time :).\n",
    "\n",
    "Everything we ave used so far was running in a single thread on your computers. Given you probably have 4 or more cores on your CPU, only one was running, other were idle.\n",
    "\n",
    "For these situations, and for those when your data don't fit your RAM, the Python ecosystem offers a solution called Dask and the combination of Dask and GeoPandas called Dask-GeoPandas. \n",
    "\n",
    "### What is Dask?\n",
    "\n",
    "From the docs:\n",
    "\n",
    "> Dask provides advanced parallelism and distributed out-of-core computation with a dask.dataframe module designed to scale pandas. Since GeoPandas is an extension to the pandas DataFrame, the same way Dask scales pandas can also be applied to GeoPandas.\n",
    "\n",
    "For more, see the [Dask tutorial](https://tutorial.dask.org).\n",
    "\n",
    "### Dask-GeoPandas\n",
    "\n",
    "We use the power of Dask and GeoPandas to run geospatial processing in parallel right now, but you can even use it to run the code on a distributed cluster and even out-of-core, when your data don't fit the memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That in practice means that we split the GeoDataFrame into multiple partitions and each is processed by a single thread. And some communication between the workers that is controlled by Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_ddf = dask_geopandas.from_geopandas(liv_lsoa, npartitions=4)\n",
    "liv_ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is done lazily as Dask expects the data may be too large, we don't see the values here. For now.\n",
    "\n",
    "The API works nearly exactly the same as we have seen above. It is just split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perimeter = liv_ddf.length\n",
    "perimeter.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liv_ddf[\"perimeter\"] = perimeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `compute()`, Dask runs all the tasks and returns the result. Same we would get from GeoPandas, just a bit faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = liv_ddf.compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How faster? Depends on the machine and operation, of course, but here is a simple example.\n",
    "\n",
    "The GeoDataFrame used above is a bit small to see any benefit from parallelization using dask (as the overhead of the task scheduler is larger than the actual operation on such a tiny dataframe), so let’s create a bigger point GeoSeries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "N = 10_000_000\n",
    "points = geopandas.GeoDataFrame(\n",
    "    geometry=geopandas.points_from_xy(numpy.random.randn(N), numpy.random.randn(N))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And creating the dask-geopandas version of this series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpoints = dask_geopandas.from_geopandas(points, npartitions=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single polygon for which we will check if the points are located within this polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.geometry\n",
    "\n",
    "box = shapely.geometry.box(0, 0, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s compare the time it takes to compute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit points.within(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit dpoints.within(box).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "This tutorial is more closely or more loosely based on the following resources:\n",
    "\n",
    "- [Introduction to GeoPandas](https://geopandas.org/en/latest/getting_started/introduction.html) by Martin Fleischmann and GeoPandas contributors\n",
    "- [GeoPandas API reference](https://geopandas.org/en/stable/docs/reference.html) by GeoPandas contributors\n",
    "- [Getting started (pandas)](https://pandas.pydata.org/docs/getting_started/index.html) by Stijn Van Hoey and pandas contributors\n",
    "- Arribas-Bel, (2019). A course on Geographic Data Science. Journal of Open Source Education, 2(14), 42, [https://doi.org/10.21105/jose.00042](https://doi.org/10.21105/jose.00042)\n",
    "- Introduction to geospatial data analysis with GeoPandas and the PyData stack bu Joris van den Bossche (https://github.com/jorisvandenbossche/geopandas-tutorial)\n",
    "- Fleischmann, M., Feliciotti, A. and Kerr, W. (2022), Evolution of Urban Patterns: Urban Morphology as an Open Reproducible Data Science. Geogr Anal, 54: 536-558. [https://doi.org/10.1111/gean.12302](https://doi.org/10.1111/gean.12302)\n",
    "- datos.gob.es [Administrative province boundaries in Catalonia](https://datos.gob.es/en/catalogo/a09002970-limites-administativos-provinciales-de-catalunya)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopython_tutorial",
   "language": "python",
   "name": "geopython_tutorial"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d1b2c984ad473d756980598d6fae8279815dc9c89a9d51a262cfb04eba7ee8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
